{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# # The GPU id to use, usually either \"0\" or \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/isha.d/.local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/isha.d/.local/lib/python3.5/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/home/isha.d/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Import Packages\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from random import shuffle\n",
    "from keras import regularizers\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation, GRU, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import imdb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Merge\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "\n",
    "## AutoRate specific packages\n",
    "import quadratic_kappa as kp\n",
    "import quadratic_kappa as q\n",
    "import normalize_features as nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to pad videos with length of frames less than 52\n",
    "def pad_videos(data, max_length):\n",
    "    arr = []; count =0\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        x = data[i]\n",
    "        if(x.shape[0] != max_length ):\n",
    "            count+=1\n",
    "            temp = []\n",
    "            for j in range(max_length - x.shape[0]):\n",
    "                temp.append(data[i][x.shape[0]-1])\n",
    "            data[i] = np.concatenate((x, temp))\n",
    "           # print(\"yes\", i, x.shape[0])\n",
    "        arr.append(data[i])\n",
    "    print(count)\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data   (1078, 52, 152) (1078, 9)\n",
      "Static data   (2161, 52, 152) (2161, 9)\n",
      "Real+Static data  (3239, 52, 152) (3239, 9)\n"
     ]
    }
   ],
   "source": [
    "video_features2_Real, ground_truth2_Real = np.load(\"features_groundTruth2/Real_Allhandpicked_features_autorate.npy\"), np.load(\"features_groundTruth2/Real_ground_truth_Allhandpicked_autorate.npy\")\n",
    "video_features2_Static, ground_truth2_Static = np.load(\"features_groundTruth2/Static_Allhandpicked_features_autorate.npy\"), np.load(\"features_groundTruth2/Static_ground_truth_Allhandpicked_autorate.npy\")\n",
    "video_features2_Real_Static, ground_truth2_Real_Static = np.concatenate((video_features2_Real, video_features2_Static)), np.concatenate((ground_truth2_Real, ground_truth2_Static))\n",
    "\n",
    "print(\"Real data  \", video_features2_Real.shape, ground_truth2_Real.shape)\n",
    "print(\"Static data  \", video_features2_Static.shape, ground_truth2_Static.shape)\n",
    "print(\"Real+Static data \", video_features2_Real_Static.shape, ground_truth2_Real_Static.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "0\n",
      "Real data  (1078, 52, 4096) (2161, 9)\n",
      "Static data  (2161, 52, 4096) (2161, 9)\n",
      "Real + Static data  (3239, 52, 4096) (4322, 9)\n"
     ]
    }
   ],
   "source": [
    "deep_features_Real, ground_truth_deep_features_Real = np.load(\"features_groundTruth2/Real_Allvggface_features_autorate.npy\"), np.load(\"features_groundTruth2/Static_ground_truth_Allvggface_autorate.npy\")\n",
    "deep_features_Static, ground_truth_deep_features_Static = np.load(\"features_groundTruth2/Static_Allvggface_features_autorate.npy\"), np.load(\"features_groundTruth2/Static_ground_truth_Allvggface_autorate.npy\")\n",
    "\n",
    "deep_features_Real = pad_videos(deep_features_Real, max_length = 52)\n",
    "deep_features_Static = pad_videos(deep_features_Static, max_length = 52)\n",
    "deep_features_Real_Static, ground_truth_deep_features_Real_Static = np.concatenate((deep_features_Real, deep_features_Static)), np.concatenate((ground_truth_deep_features_Real, ground_truth_deep_features_Static))\n",
    "\n",
    "#######################3 Pad deep features ##################\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "deep_features_Real_Static = pad_videos(deep_features_Real_Static, max_length = 52)\n",
    "\n",
    "print(\"Real data \", deep_features_Real.shape, ground_truth_deep_features_Real.shape)\n",
    "print(\"Static data \", deep_features_Static.shape, ground_truth_deep_features_Static.shape)\n",
    "print(\"Real + Static data \", deep_features_Real_Static.shape, ground_truth_deep_features_Real_Static.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3239, 52, 152) (3239, 9)\n",
      "(3239, 52, 4096) (4322, 9)\n"
     ]
    }
   ],
   "source": [
    "video_features2, ground_truth2 = video_features2_Real_Static, ground_truth2_Real_Static\n",
    "deep_features, ground_truth_deep_features = deep_features_Real_Static, ground_truth_deep_features_Real_Static\n",
    "print(video_features2.shape, ground_truth2.shape)\n",
    "print(deep_features.shape, ground_truth_deep_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y):\n",
    "    \n",
    "    temp_X, temp_y = [], []\n",
    "    x = np.arange(len(X))\n",
    "    shuffle(x)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        temp_X.append(X[x[i]])\n",
    "        temp_y.append(y[x[i]])\n",
    "        \n",
    "    return np.array(temp_X), np.array(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_features = deep_features_Real_Static\n",
    "ground_truth = ground_truth_deep_features_Real_Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_area(data):\n",
    "    temp =[]\n",
    "    for i in range(len(data)):\n",
    "        x= data[i]\n",
    "        for j in range(len(x)):\n",
    "            if(x[j]<0):\n",
    "                x[j]=0\n",
    "        \n",
    "        area = (x[3]-x[1])*(x[2]-x[0])\n",
    "        temp.append(area)\n",
    "        \n",
    "    return np.array(temp)\n",
    "\n",
    "def compute_face_area(arr):\n",
    "    temp =[]\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        temp.append(face_area(arr[i]))\n",
    "        \n",
    "    return np.array(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Features + Hand Picked features (3239, 52, 4244) (3239, 9)\n"
     ]
    }
   ],
   "source": [
    "video_features_combined = np.concatenate((deep_features, video_features2[:,:,1].astype(float).reshape(video_features2.shape[0],video_features2.shape[1],1),compute_face_area(video_features2[:,:,2:6].astype(float)).reshape(video_features2.shape[0],video_features2.shape[1],1),video_features2[:,:,6:].astype(float) ),axis=2)\n",
    "ground_truth_combined = ground_truth2\n",
    "print(\"Deep Features + Hand Picked features\", video_features_combined.shape, ground_truth_combined.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2105, 52, 4244) (2105, 9) (567, 52, 4244) (567, 9) (567, 52, 4244) (567, 9)\n"
     ]
    }
   ],
   "source": [
    "## Divide the data into train, val and test\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(video_features_combined, ground_truth_combined, test_size=0.35)\n",
    "X_val, X_test, y_val, y_test = train_test_split( X_test1, y_test1, test_size=0.5)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  5.14040000e+04, -7.36480800e+00, -9.18400100e+00,\n",
       "        5.19215470e+01, -3.67854595e+00, -2.42124939e+00,  0.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.95892615e-01,  1.10807528e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_features_combined[0,0,4096:4108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video = X_train[:,:,:4096]\n",
    "val_video= X_val[:,:,:4096]\n",
    "test_video = X_test[:,:,:4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import normalize_features as nf\n",
    "\n",
    "X_train_mod_specific_normalized, X_val_mod_specific_normalized = nf.inter_normalization(X_train[:,:,4096:], X_val[:,:,4096:])\n",
    "X_train_mod_specific_normalized, X_test_mod_specific_normalized = nf.inter_normalization(X_train[:,:,4096:], X_test[:,:,4096:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_train_mod_specific_normalized.reshape(X_train.shape[0]*X_train.shape[1], X_train_mod_specific_normalized.shape[2])\n",
    "y=  np.min(x[:,:12].astype(float),axis =0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN + Handpicked features on0 train data (2105, 52, 4244)\n",
      "CNN + Handpicked features on val data (567, 52, 4244)\n",
      "CNN + Handpicked features on test data (567, 52, 4244)\n"
     ]
    }
   ],
   "source": [
    "X_train_mod = np.concatenate((train_video , X_train_mod_specific_normalized), axis =2)\n",
    "X_val_mod = np.concatenate((val_video , X_val_mod_specific_normalized), axis =2)\n",
    "X_test_mod = np.concatenate((test_video , X_test_mod_specific_normalized), axis =2)\n",
    "\n",
    "print(\"CNN + Handpicked features on0 train data\", X_train_mod.shape)\n",
    "print(\"CNN + Handpicked features on val data\", X_val_mod.shape)\n",
    "print(\"CNN + Handpicked features on test data\", X_test_mod.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mod = np.load('data/X_train_mod_vggface.npy')\n",
    "X_val_mod = np.load('data/X_val_mod_vggface.npy')\n",
    "X_test_mod = np.load('data/X_test_mod_vggface.npy')\n",
    "y_train = np.load('data/y_train_vggface.npy')\n",
    "y_val = np.load('data/y_val_vggface.npy')\n",
    "y_test= np.load('data/y_test_vggface.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train_mod\n",
    "train_label = y_train[:,7].astype(float).astype(int)\n",
    "val_data = X_val_mod\n",
    "test_data = X_test_mod\n",
    "val_label = y_val[:,7].astype(float).astype(int)\n",
    "test_label = y_test[:,7].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_categorical = keras.utils.to_categorical(train_label - 1)\n",
    "val_label_categorical = keras.utils.to_categorical(val_label - 1)\n",
    "test_label_categorical = keras.utils.to_categorical(test_label - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Attention LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fake = Faker()\n",
    "fake.seed(12345)\n",
    "random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(52)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor_left1 = Dense(10, activation = \"tanh\", name='DenseLeft1')\n",
    "densor_left2 = Dense(1, activation = \"relu\", name='DenseLeft2')\n",
    "activator_left = Activation(softmax, name='attention_weights_left') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(52)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor_right1 = Dense(10, activation = \"tanh\", name='DenseRight1')\n",
    "densor_right2 = Dense(1, activation = \"relu\", name='DenseRight2')\n",
    "activator_right = Activation(softmax, name='attention_weights_right') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_step_attention\n",
    "\n",
    "def one_step_attention_left(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e = densor_left1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies = densor_left2(e)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator_left(energies)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas, a])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_step_attention\n",
    "\n",
    "def one_step_attention_right(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e_right = densor_right1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies_right = densor_right2(e_right)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator_right(energies_right)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas, a])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(16, activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model_left(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size, i):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size), name= 'X'+str(i))\n",
    "    s0 = Input(shape=(n_s,), name='s0'+str(i))\n",
    "    c0 = Input(shape=(n_s,), name='c0'+str(i))\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True, name='bidirectional_1_left'), merge_mode='concat')(X)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
    "        context = one_step_attention_left(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s, c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs=(X, s0, c0), outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model_right(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size, i):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size), name= 'X'+str(i))\n",
    "    s0 = Input(shape=(n_s,), name='s0'+str(i))\n",
    "    c0 = Input(shape=(n_s,), name='c0'+str(i))\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True, name='bidirectional_1_right'), merge_mode='concat')(X)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
    "        context = one_step_attention_right(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s, c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs=(X, s0, c0), outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/isha.d/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/isha.d/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/isha.d/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1213: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "model1 = model_left(52, 1, n_a, n_s, 4096, 5,0)\n",
    "model2 = model_right(52, 1, n_a, n_s, 12, 5,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,114,943\n",
      "Trainable params: 1,114,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isha.d/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([model1, model2], mode = 'concat'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈2 lines)\n",
    "from keras import optimizers\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((train_data.shape[0], n_s))\n",
    "c0 = np.zeros((train_data.shape[0], n_s))\n",
    "train_label_categorical2 =train_label_categorical.reshape((train_data.shape[0],1,5))\n",
    "train_label_categorical2 = list(train_label_categorical2.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.zeros((val_data.shape[0], n_s))\n",
    "c1 = np.zeros((val_data.shape[0], n_s))\n",
    "val_label_categorical2 =val_label_categorical.reshape((val_data.shape[0],1,5))\n",
    "val_label_categorical2 = list(val_label_categorical2.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopping = keras.callbacks.EarlyStopping(monitor = 'val_loss',min_delta = 0.01, patience =3, verbose =1, mode ='auto')\n",
    "\n",
    "# history = model.fit([train_data, s0, c0], train_label_categorical2, epochs=200, batch_size=40, callbacks=[earlystopping],\n",
    "#         class_weight = 'balanced',validation_data=([val_data, s1, c1], val_label_categorical2), verbose=1, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/isha.d/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/isha.d/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 2105 samples, validate on 567 samples\n",
      "Epoch 1/200\n",
      "2105/2105 [==============================] - 23s 11ms/step - loss: 1.4969 - acc: 0.3667 - val_loss: 1.3933 - val_acc: 0.4339\n",
      "Epoch 2/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 1.2111 - acc: 0.5530 - val_loss: 1.0729 - val_acc: 0.5908\n",
      "Epoch 3/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 0.9721 - acc: 0.6361 - val_loss: 0.9973 - val_acc: 0.6296\n",
      "Epoch 4/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 0.8274 - acc: 0.6836 - val_loss: 0.8956 - val_acc: 0.6596\n",
      "Epoch 5/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 0.7589 - acc: 0.6969 - val_loss: 0.7866 - val_acc: 0.6755\n",
      "Epoch 6/200\n",
      "2105/2105 [==============================] - 16s 8ms/step - loss: 0.7015 - acc: 0.7207 - val_loss: 0.9246 - val_acc: 0.6226\n",
      "Epoch 7/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 0.6387 - acc: 0.7515 - val_loss: 0.7718 - val_acc: 0.6966\n",
      "Epoch 8/200\n",
      "2105/2105 [==============================] - 16s 8ms/step - loss: 0.5816 - acc: 0.7729 - val_loss: 0.7408 - val_acc: 0.7125\n",
      "Epoch 9/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 0.5393 - acc: 0.7957 - val_loss: 0.7779 - val_acc: 0.6949\n",
      "Epoch 10/200\n",
      "2105/2105 [==============================] - 16s 8ms/step - loss: 0.4864 - acc: 0.8209 - val_loss: 0.6690 - val_acc: 0.7266\n",
      "Epoch 11/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 0.4591 - acc: 0.8333 - val_loss: 0.7338 - val_acc: 0.7143\n",
      "Epoch 12/200\n",
      "2105/2105 [==============================] - 16s 8ms/step - loss: 0.4451 - acc: 0.8404 - val_loss: 0.6899 - val_acc: 0.7390\n",
      "Epoch 13/200\n",
      "2105/2105 [==============================] - 17s 8ms/step - loss: 0.3949 - acc: 0.8466 - val_loss: 0.7426 - val_acc: 0.7072\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit([train_data[:,:,:4096], s0, c0, train_data[:,:,4096:4108], s0, c0], train_label_categorical2, epochs=200, batch_size=40, callbacks=[earlystopping],\n",
    "        class_weight = 'balanced',validation_data=([val_data[:,:,:4096], s1, c1, val_data[:,:,4096:4108], s1, c1], val_label_categorical2), verbose=1, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isha.d/.local/lib/python3.5/site-packages/keras/engine/topology.py:2344: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 's00:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'c00:0' shape=(?, 64) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n",
      "/home/isha.d/.local/lib/python3.5/site-packages/keras/engine/topology.py:2344: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 's01:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'c01:0' shape=(?, 64) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"weights/AttentionLSTM-Merge_VGGFace/weights.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"weights/AttentionLSTM-Merge_VGGFace/weights.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 0 3 4 0 4 4 0 4 0 0 3 4 0] [4 0 0 3 3 0 4 4 0 4 1 0 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([val_data[:15,:,:4096], s0, c0, val_data[:15,:,4096:4108], s0, c0])\n",
    "prediction = np.argmax(prediction, axis = -1)\n",
    "print(prediction, np.argmax(val_label_categorical[:15], axis =1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, label):\n",
    "    prediction = model.predict([data[:,:,:4096], s0, c0, data[:,:,4096:4108], s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)+1\n",
    "    acc =0; s=0\n",
    "    for i in range(len(label)):\n",
    "        if(prediction[i]==label[i]):\n",
    "            s+=1\n",
    "    acc = (s*100)/len(label)\n",
    "    print(\"Accuracy\", acc)\n",
    "    \n",
    "    print(confusion_matrix(prediction, label))\n",
    "    print(classification_report(prediction, label))\n",
    "    return acc, np.concatenate((np.array(label).reshape((len(label),1)), np.array(prediction).reshape((len(prediction),1))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 88.74109263657957\n",
      "[[510   7   0   1   2]\n",
      " [  0 150  40   0   0]\n",
      " [  0  27 162  20   0]\n",
      " [  3   6  71 305  41]\n",
      " [  0   0   0  19 741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.98      0.99       520\n",
      "           2       0.79      0.79      0.79       190\n",
      "           3       0.59      0.78      0.67       209\n",
      "           4       0.88      0.72      0.79       426\n",
      "           5       0.95      0.97      0.96       760\n",
      "\n",
      "    accuracy                           0.89      2105\n",
      "   macro avg       0.84      0.85      0.84      2105\n",
      "weighted avg       0.90      0.89      0.89      2105\n",
      "\n",
      "Accuracy 70.72310405643739\n",
      "[[116   8   1   3   0]\n",
      " [  1  25  10   4   1]\n",
      " [  1  16  33   9   3]\n",
      " [  2   4  24  54  49]\n",
      " [  2   1   3  24 173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.91      0.93       128\n",
      "           2       0.46      0.61      0.53        41\n",
      "           3       0.46      0.53      0.50        62\n",
      "           4       0.57      0.41      0.48       133\n",
      "           5       0.77      0.85      0.81       203\n",
      "\n",
      "    accuracy                           0.71       567\n",
      "   macro avg       0.64      0.66      0.65       567\n",
      "weighted avg       0.71      0.71      0.70       567\n",
      "\n",
      "Accuracy 71.42857142857143\n",
      "[[155   3   0   0   1]\n",
      " [  2  23  11   4   1]\n",
      " [  1   9  28  14   3]\n",
      " [  0   9  31  43  41]\n",
      " [  0   0   4  28 156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.97      0.98       159\n",
      "           2       0.52      0.56      0.54        41\n",
      "           3       0.38      0.51      0.43        55\n",
      "           4       0.48      0.35      0.40       124\n",
      "           5       0.77      0.83      0.80       188\n",
      "\n",
      "    accuracy                           0.71       567\n",
      "   macro avg       0.63      0.64      0.63       567\n",
      "weighted avg       0.71      0.71      0.71       567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_prediction = evaluate_model(train_data, train_label)\n",
    "val_acc, val_prediction = evaluate_model(val_data, val_label)\n",
    "test_acc, test_prediction= evaluate_model(test_data, test_label)\n",
    "# print(train_acc, val_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa on training data [[0.90471601]\n",
      " [0.91587337]\n",
      " [0.9374438 ]\n",
      " [0.93172433]\n",
      " [0.91312883]\n",
      " [0.97114205]\n",
      " [0.92057727]]\n",
      "Kappa on validation data [[0.83986495]\n",
      " [0.8733425 ]\n",
      " [0.87734182]\n",
      " [0.87531295]\n",
      " [0.85872931]\n",
      " [0.89385428]\n",
      " [0.86491831]]\n",
      "Kappa on testing data [[0.86630043]\n",
      " [0.88843758]\n",
      " [0.90345331]\n",
      " [0.89686384]\n",
      " [0.86203426]\n",
      " [0.91895032]\n",
      " [0.88341788]]\n"
     ]
    }
   ],
   "source": [
    "import quadratic_kappa as q\n",
    "\n",
    "def eval_kappa(gt_file, data):\n",
    "    eval_new = np.concatenate((gt_file[:,1:6], data),axis =1)\n",
    "    eval_all = eval_new[:,:7].astype(float).astype(int)\n",
    "    kappa_values =[]\n",
    "    for i in range(6):\n",
    "        r1 = eval_all[:,i]\n",
    "        p1 = eval_all[:,6]\n",
    "        #print(r1,p1)\n",
    "        arr = np.concatenate((r1.reshape(len(r1),1),p1.reshape(len(p1),1)),axis =1)\n",
    "        qkappa1 = q.quadratic_kappa(arr, arr.shape[1])\n",
    "        #print(qkappa1)\n",
    "        kappa_values.append(qkappa1)\n",
    "\n",
    "    #print(np.array(kappa_values).shape)\n",
    "    kappa_values.append(np.mean(np.array(kappa_values)[:5]))\n",
    "    return kappa_values\n",
    "\n",
    "training =np.array(eval_kappa(y_train, train_prediction))\n",
    "validation = np.array(eval_kappa(y_val, val_prediction))\n",
    "testing = np.array(eval_kappa(y_test, test_prediction))\n",
    "\n",
    "print(\"Kappa on training data\", training.reshape(len(training),1))\n",
    "print(\"Kappa on validation data\", validation.reshape(len(validation),1))\n",
    "print(\"Kappa on testing data\", testing.reshape(len(testing),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(video, ground_truth):\n",
    "    n_s = 64;\n",
    "    num = 7; Tx = 52; Ty =1\n",
    "    \n",
    "    attention_map = np.zeros((1, 52))\n",
    "    attention_map2 = np.zeros((1, 52))\n",
    "    attention_map3 = np.zeros((12, 52))\n",
    "    attention_map5 = np.zeros((52,12))\n",
    "    attention_map4 = np.zeros(( 12,1))\n",
    "    \n",
    "    Ty, Tx = attention_map.shape\n",
    "    Ty2, Tx2 = attention_map2.shape\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    \n",
    "    layer1 = model1.layers[7]\n",
    "    layer2 = model2.layers[7]\n",
    "    layer3 = model2.layers[0]\n",
    "    \n",
    "    f1 = K.function(model1.inputs, [layer1.get_output_at(t) for t in range(Ty)])\n",
    "    r1 = f1([video[:,:4096].reshape(1,52, 4096), s0, c0])\n",
    "    \n",
    "    f2 = K.function(model2.inputs, [layer2.get_output_at(t) for t in range(Ty)])\n",
    "    r2 = f2([video[:,4096:4108].reshape(1,52, 12), s0, c0])\n",
    "    \n",
    "    f3 = K.function(model2.inputs, [layer3.get_output_at(t) for t in range(Ty)])\n",
    "    r3 = f3([video[:,4096:4108].reshape(1,52, 12), s0, c0])\n",
    "  \n",
    "   # print(np.array(r2).shape,np.array(r3).shape)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r1[t][0,t_prime,0]\n",
    "            \n",
    "    for t1 in range(Ty):\n",
    "        for t_prime1 in range(Tx):\n",
    "            attention_map2[t1][t_prime1] = r2[t1][0,t_prime1,0]\n",
    "            \n",
    "    for t2 in range(12):\n",
    "        for t_prime2 in range(Tx): \n",
    "            attention_map3[t2][t_prime2] = r3[0][0,t_prime2,t2]\n",
    "            \n",
    "#     print(attention_map3.shape, attention_map3[0,:])\n",
    "            \n",
    "   # print(attention_map)\n",
    "    prediction = model.predict([video[:,:4096].reshape((1,52, 4096)), s0, c0,video[:,4096:4108].reshape((1,52, 12)), s0, c0])\n",
    "    predicted_text = []\n",
    "    for i in range(len(prediction)):\n",
    "    #print(i)\n",
    "        predicted_text.append(int(np.argmax(prediction[i])))\n",
    "    print(\" Actual is ==> \",ground_truth[7].astype(float).astype(int),\"predicted is ==> \",predicted_text[0]+1 )\n",
    "   \n",
    "\n",
    "    # Plot the attention_map\n",
    "    #plt.clf()\n",
    "    plt.figure(figsize=(80, 60))\n",
    "    plt.axis('off')\n",
    "#     h =plt.ylabel('Generic Features', fontsize=65, labelpad = 260)\n",
    "#     h.set_rotation(0)\n",
    "    plt.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "    #plt.clf()\n",
    "    plt.figure(figsize=(80, 60))\n",
    "    plt.axis('off')\n",
    "#     h =plt.ylabel('Specific Features', fontsize=65, labelpad = 260)\n",
    "#     h.set_rotation(0)\n",
    "    i = plt.imshow(attention_map2, interpolation='nearest', cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "    for i in range(attention_map3.shape[0]):\n",
    "        attention_map4 = attention_map3[i,:].reshape((1,52))\n",
    "        plt.figure(figsize=(80, 60))\n",
    "        #plt.add_subplot(1, 1, 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(attention_map4,  interpolation='nearest', cmap='Oranges')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l =['Face Detection', 'Face Area', 'Roll', 'Pitch', 'Yaw', 'EyeGaze_x', 'EyeGaze_y', 'Phone', 'Seatbelt', 'Landmark', 'EAR', 'MAR']\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def plot_frames(x):\n",
    "    i =1; im2 = []\n",
    "    while(i<=52):\n",
    "        if(i<=9):\n",
    "            name = \"0000\" +str(i)\n",
    "        elif(i<=99):\n",
    "            name = \"000\" + str(i)\n",
    "        \n",
    "        filename = x +\"/output_\" + name +\".png\"\n",
    "        #print(filename)\n",
    "        im = Image.open(filename)\n",
    "        if(i ==1):\n",
    "            im2 = im \n",
    "            i=i+4\n",
    "            continue\n",
    "        im2 = np.concatenate((im2, im),axis =1)\n",
    "        i = i+4\n",
    "\n",
    "    plt.figure(figsize=(80, 400))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(im2, interpolation='nearest', cmap='Blues')\n",
    "    plt.show()\n",
    "    #return im2\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_names(ground_truth_data):\n",
    "    video_names = ground_truth_data[:,0]\n",
    "    video_names_processed = []; video_final_list = []\n",
    "\n",
    "    for i in range(len(video_names)):\n",
    "            video_data = list(video_names[i].replace(\"./data/\",\"\").split(\"/\"))\n",
    "            video_data = list(filter(None, video_data))\n",
    "            video_names_processed.append(video_data)\n",
    "\n",
    "    video_names_processed = np.array(video_names_processed)\n",
    "    video_data_names =  video_names_processed\n",
    "\n",
    "    for i in range(len(video_data_names)):\n",
    "        video = np.array(video_data_names[i])\n",
    "        #print(i, len(video))\n",
    "        if(len(video)<3):\n",
    "            input_feature = \"/ssd_scratch/cvit/isha2/dataset/hams_dataset1_processed3/\" +str(video[0])+\"/\" + str(video[1])[:-4] +\".mp4\"\n",
    "        \n",
    "        elif(len(video)==3):\n",
    "            input_feature = \"/ssd_scratch/cvit/isha2/dataset/\" + str(video[0]) +\"/\"  +str(video[1]) +\"/\" + str(video[2])[:-4] +\".mp4\"\n",
    "           # print(input_feature)\n",
    "        if(os.path.exists(input_feature)):\n",
    "            video_final_list.append(input_feature)\n",
    " \n",
    "    return video_final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = video_names(ground_truth_combined)\n",
    "# k =0\n",
    "# for i in range(1):\n",
    "#     k = i*20\n",
    "#     !ffmpeg -i \"{x[k]}\"   -loglevel panic dataset/output_%05d.png\n",
    "#     plot_frames(\"dataset/\")\n",
    "#     plot_map(video_features_combined[k], ground_truth_combined[k])\n",
    "#     print(\"\\n \\n \\n\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = video_names(ground_truth_combined)\n",
    "# k = 1500\n",
    "# for i in range(20):\n",
    "#     k = k + 40\n",
    "#     !ffmpeg -i \"{x[k]}\"   -loglevel panic dataset/output_%05d.png\n",
    "#     plot_frames(\"dataset/\")\n",
    "#     plot_map(video_features_combined[k], ground_truth_combined[k])\n",
    "#     print(\"\\n \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_value(video, ground_truth):\n",
    "    n_s = 64;\n",
    "    num = 7; Tx = 52; Ty =1\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    \n",
    "    # print(attention_map)\n",
    "    prediction = model.predict([video[:,:4096].reshape((1,52, 4096)), s0, c0,video[:,4096:4108].reshape((1,52, 12)), s0, c0])\n",
    "    predicted_text = []\n",
    "    for i in range(len(prediction)):\n",
    "    #print(i)\n",
    "        predicted_text.append(int(np.argmax(prediction[i])))\n",
    "\n",
    "    return ground_truth[7].astype(float).astype(int), predicted_text[0]+1 \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def create_dynamic_videos(video, ground_truth):\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "#     for j in range(52):\n",
    "#         print(j)\n",
    "#         plt.style.use('dark_background')\n",
    "#         img1 = mpimg.imread('dataset/output_'+str(j+1).zfill(5)+'.png')\n",
    "#         plt.figure(figsize=(8, 8)) \n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(img1)\n",
    "#         plt.savefig('faltu/img1_'+str(j+1)+'.png', bbox_inches=\"tight\", pad_inches=0, transparent= True)\n",
    "#         plt.close()\n",
    "\n",
    "    xdata1 = []; ydata1 = []; \n",
    "    xdata2 = []; ydata2 = [];\n",
    "    xdata3 = []; ydata3 = [];\n",
    "    xdata4 = []; ydata4 = [];\n",
    "    xdata5 = []; ydata5 = [];\n",
    "    xdata6 = []; ydata6 = [];\n",
    "    xdata7 = []; ydata7 = [];\n",
    "    xdata8 = []; ydata8 = [];\n",
    "    xdata9 = []; ydata9 = [];\n",
    "    xdata10 = []; ydata10 = [];\n",
    "    #plt.show() \n",
    "\n",
    "    for i in range(52):\n",
    "        print(i)\n",
    "        fig = plt.figure(figsize=(12,10),frameon=True)\n",
    "        ax = fig.subplots(10, 1)\n",
    "       #fig.tight_layout()\n",
    "\n",
    "        ax[0].set_xlim(0, 52)\n",
    "        #ax[0].set_ylim(0, 329400)\n",
    "        ax[0].locator_params(axis='y', nbins=3)\n",
    "        ax[0].set_ylabel('Face Area', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[0].plot(xdata1, ydata1, 'g-', linewidth=4.0)\n",
    "        xdata1.append(i)\n",
    "        ydata1.append(video[i,4097])\n",
    "        line.set_xdata(xdata1)\n",
    "        line.set_ydata(ydata1)\n",
    "\n",
    "        ax[1].set_xlim(0, 52)\n",
    "        #ax[1].set_ylim(-180, 180)\n",
    "        ax[1].locator_params(axis='y', nbins=3)\n",
    "        ax[1].set_ylabel('Roll', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[1].plot(xdata2, ydata2, 'g-', linewidth=4.0)\n",
    "        xdata2.append(i)\n",
    "        ydata2.append(video[i,4098])\n",
    "        line.set_xdata(xdata2)\n",
    "        line.set_ydata(ydata2)\n",
    "\n",
    "\n",
    "        ax[2].set_xlim(0, 52)\n",
    "       # ax[2].set_ylim(-180, 180)\n",
    "        ax[2].locator_params(axis='y', nbins=3)\n",
    "        ax[2].set_ylabel('Pitch', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[2].plot(xdata3, ydata3, 'g-', linewidth=4.0)\n",
    "        xdata3.append(i)\n",
    "        ydata3.append(video[i,4099])\n",
    "        line.set_xdata(xdata3)\n",
    "        line.set_ydata(ydata3)\n",
    "\n",
    "        ax[3].set_xlim(0, 52)\n",
    "       # ax[3].set_ylim(-180, 180)\n",
    "        ax[3].locator_params(axis='y', nbins=3)\n",
    "        ax[3].set_ylabel('Yaw', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[3].plot(xdata4, ydata4, 'g-', linewidth=4.0)\n",
    "        xdata4.append(i)\n",
    "        ydata4.append(video[i,4100])\n",
    "        line.set_xdata(xdata4)\n",
    "        line.set_ydata(ydata4)\n",
    "\n",
    "\n",
    "        ax[4].set_xlim(0, 52)\n",
    "       # ax[4].set_ylim(-180, 180)\n",
    "        ax[4].locator_params(axis='y', nbins=3)\n",
    "        ax[4].set_ylabel('EyeGaze_X', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[4].plot(xdata5, ydata5, 'g-', linewidth=4.0)\n",
    "        xdata5.append(i)\n",
    "        ydata5.append(video[i,4101])\n",
    "        line.set_xdata(xdata5)\n",
    "        line.set_ydata(ydata5)\n",
    "\n",
    "        ax[5].set_xlim(0, 52)\n",
    "       # ax[5].set_ylim(-180, 180)\n",
    "        ax[5].locator_params(axis='y', nbins=3)\n",
    "        ax[5].set_ylabel('EyeGaze_Y', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[5].plot(xdata6, ydata6, 'g-', linewidth=4.0)\n",
    "        xdata6.append(i)\n",
    "        ydata6.append(video[i,4102])\n",
    "        line.set_xdata(xdata6)\n",
    "        line.set_ydata(ydata6)\n",
    "\n",
    "        if(int(video[i,4103]) == 0):\n",
    "            ax[6].set_xlim(0, 52)\n",
    "           # ax[6].set_ylim(0,1)\n",
    "            ax[6].locator_params(axis='y', nbins=3)\n",
    "            ax[6].set_ylabel('Phone', rotation=0, fontsize=20, labelpad=60)\n",
    "            line, = ax[6].plot(xdata7, ydata7, 'g-', linewidth=4.0)\n",
    "            xdata7.append(i)\n",
    "            ydata7.append(video[i,4103])\n",
    "            line.set_xdata(xdata7)\n",
    "            line.set_ydata(ydata7)\n",
    "            \n",
    "        elif(int(video[i,4103]) == 1):\n",
    "            ax[6].set_xlim(0, 52)\n",
    "           # ax[6].set_ylim(0,1)\n",
    "            ax[6].locator_params(axis='y', nbins=3)\n",
    "            ax[6].set_ylabel('Phone', rotation=0, fontsize=20, labelpad=60)\n",
    "            line, = ax[6].plot(xdata7, ydata7, 'r-', linewidth=4.0)\n",
    "            xdata7.append(i)\n",
    "            ydata7.append(video[i,4103])\n",
    "            line.set_xdata(xdata7)\n",
    "            line.set_ydata(ydata7)\n",
    "\n",
    "        if(int(video[i,4104]) == 1):\n",
    "            ax[7].set_xlim(0, 52)\n",
    "           # ax[7].set_ylim(0,1)\n",
    "            ax[7].locator_params(axis='y', nbins=3)\n",
    "            ax[7].set_ylabel('Seatbelt', rotation=0, fontsize=20, labelpad=60)\n",
    "            line, = ax[7].plot(xdata8, ydata8, 'g-', linewidth=4.0)\n",
    "            xdata8.append(i)\n",
    "            ydata8.append(video[i,4104])\n",
    "            line.set_xdata(xdata8)\n",
    "            line.set_ydata(ydata8)\n",
    "\n",
    "        elif(int(video[i,4104]) == 0):\n",
    "            ax[7].set_xlim(0, 52)\n",
    "           # ax[7].set_ylim(0,1)\n",
    "            ax[7].locator_params(axis='y', nbins=3)\n",
    "            ax[7].set_ylabel('Seatbelt', rotation=0, fontsize=20, labelpad=60)\n",
    "            line, = ax[7].plot(xdata8, ydata8, 'r-', linewidth=4.0)\n",
    "            xdata8.append(i)\n",
    "            ydata8.append(video[i,4104])\n",
    "            line.set_xdata(xdata8)\n",
    "            line.set_ydata(ydata8)\n",
    "            \n",
    "            \n",
    "        ax[8].set_xlim(0, 52)\n",
    "       # ax[8].set_ylim(0,10)\n",
    "        ax[8].locator_params(axis='y', nbins=3)\n",
    "        ax[8].set_ylabel('EAR', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[8].plot(xdata9, ydata9, 'g-', linewidth=4.0)\n",
    "        xdata9.append(i)\n",
    "        ydata9.append(video[i,4106])\n",
    "        line.set_xdata(xdata9)\n",
    "        line.set_ydata(ydata9)\n",
    "\n",
    "        ax[9].set_xlim(0, 52)\n",
    "       # ax[9].set_ylim(0,10)\n",
    "        ax[9].locator_params(axis='y', nbins=3)\n",
    "        ax[9].set_ylabel('MAR', rotation=0, fontsize=20, labelpad=60)\n",
    "        line, = ax[9].plot(xdata10, ydata10, 'g-', linewidth=4.0)\n",
    "        xdata10.append(i)\n",
    "        ydata10.append(video[i,4107])\n",
    "        line.set_xdata(xdata10)\n",
    "        line.set_ydata(ydata10)\n",
    "\n",
    "        fig.savefig('faltu/img2_'+str(i+1)+'.png', bbox_inches=\"tight\", pad_inches=0.2, transparent= False)\n",
    "        plt.close(fig)\n",
    "\n",
    "    plt.close(fig)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img(video_features, ground_truth):\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in range(52):\n",
    "        plt.style.use('dark_background')\n",
    "        img1 = cv2.imread('dataset/output_'+str(i+1).zfill(5)+'.png')\n",
    "        img2 = cv2.copyMakeBorder(img1, 100,50, 50, 50, cv2.BORDER_CONSTANT,value=color)   \n",
    "        gt, pred = predicted_value(video_features, ground_truth)\n",
    "        \n",
    "        cv2.putText(img2,'Actual Rating',(40,30), font, 0.7,(0,255,0),2)\n",
    "        cv2.putText(img2,str(gt),(200,30), font, 0.7,(0,255,0),2)\n",
    "        cv2.putText(img2,'Predicted Rating',(40,70), font, 0.7,(0,255,0),2)\n",
    "        cv2.putText(img2,str(pred),(230,70), font, 0.7,(0,255,0),2)\n",
    "        \n",
    "        cv2.imwrite('faltu/img1_'+str(i+1)+'.png', img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "x = video_names(ground_truth_combined)\n",
    "k =0; color = [0, 0, 0]\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "    out = cv2.VideoWriter('output/out'+str(i+1)+'.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 3, (1200,600))\n",
    "    k = i*20\n",
    "    !ffmpeg -i \"{x[k]}\" -loglevel panic dataset/output_%05d.png\n",
    "    \n",
    "    create_dynamic_videos(video_features_combined[k], ground_truth_combined[k])\n",
    "    write_img(video_features_combined[k], ground_truth_combined[k])\n",
    "    \n",
    "    for l in range(52):\n",
    "        im1 = cv2.imread('faltu/img1_'+str(l+1)+'.png')\n",
    "        im2 = cv2.imread('faltu/img2_'+str(l+1)+'.png')\n",
    "        im3 = cv2.resize(im1, ( im1.shape[1],600))\n",
    "        im4 = cv2.resize(im2, (im2.shape[1], 600))\n",
    "      #  im3 = cv2.copyMakeBorder(im3, 100,50, 50, 50, cv2.BORDER_CONSTANT,value=color)\n",
    "        im5 = cv2.resize(np.concatenate((im3,im4), axis =1),(1200,600))\n",
    "        out.write(im5)\n",
    "       # cv2.imwrite('im5.png', im5)\n",
    "        \n",
    "    out.release()\n",
    "    print(\"\\n \\n \\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "x = video_names(ground_truth_combined)\n",
    "k =1500; color = [0, 0, 0]; i=20\n",
    "\n",
    "\n",
    "while(i < 40):\n",
    "\n",
    "    # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "    out = cv2.VideoWriter('output/out'+str(i+1)+'.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 3, (1200,600))\n",
    "    k = k + 40\n",
    "    !ffmpeg -i \"{x[k]}\" -loglevel panic dataset/output_%05d.png\n",
    "    \n",
    "    create_dynamic_videos(video_features_combined[k], ground_truth_combined[k])\n",
    "    write_img(video_features_combined[k], ground_truth_combined[k])\n",
    "    \n",
    "    for l in range(52):\n",
    "        im1 = cv2.imread('faltu/img1_'+str(l+1)+'.png')\n",
    "        im2 = cv2.imread('faltu/img2_'+str(l+1)+'.png')\n",
    "        im3 = cv2.resize(im1, ( im1.shape[1],600))\n",
    "        im4 = cv2.resize(im2, (im2.shape[1], 600))\n",
    "      #  im3 = cv2.copyMakeBorder(im3, 100,50, 50, 50, cv2.BORDER_CONSTANT,value=color)\n",
    "        im5 = cv2.resize(np.concatenate((im3,im4), axis =1),(1200,600))\n",
    "        out.write(im5)\n",
    "       # cv2.imwrite('im5.png', im5)\n",
    "        \n",
    "    out.release()\n",
    "    print(\"\\n \\n \\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_video(video, ground_truth):\n",
    "#     n_s = 64;\n",
    "#     num = 7; Tx = 52; Ty =1\n",
    "#     s0 = np.zeros((1, n_s))\n",
    "#     c0 = np.zeros((1, n_s))\n",
    "    \n",
    "#     prediction = model.predict([video[:,:4096].reshape((1,52, 4096)), s0, c0,video[:,4096:4108].reshape((1,52, 12)), s0, c0])\n",
    "#     predicted_text = []\n",
    "#     for i in range(len(prediction)):\n",
    "#     #print(i)\n",
    "#         predicted_text.append(int(np.argmax(prediction[i])))\n",
    "#     print(\" Actual is ==> \",ground_truth[7].astype(float).astype(int),\"predicted is ==> \",predicted_text[0]+1 )\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# def create_videos(video, ground_truth):\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     for i in range(52):\n",
    "#         plt.style.use('dark_background')\n",
    "\n",
    "#         img1 = cv2.imread('dataset/output_'+str(i+1).zfill(5)+'.png')\n",
    "#         img2 = np.zeros((int(img1.shape[0]), int(img1.shape[1]), int(img1.shape[2])), np.uint8)\n",
    "\n",
    "#         cv2.putText(img2,'Actual Rating',(20,40), font, 0.7,(0,0,255),2)\n",
    "#         cv2.putText(img2,'Predicted Rating',(20,80), font, 0.7,(0,0,255),2)\n",
    "\n",
    "    \n",
    "    \n",
    "#         img3 = np.concatenate((img1,img2), axis =1)\n",
    "#         # img4 = np.zeros((int(img3.shape[0]/2), int(img3.shape[1]), int(img3.shape[2])), np.uint8)\n",
    "\n",
    "#         # img5 = np.concatenate((img1,img2), axis =0)\n",
    "#         #Display the image\n",
    "#         plt.figure(figsize=(8, 10))\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(img3)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# def create_dynamic_plot(img, video_features):\n",
    "#     plt.style.use('dark_background')\n",
    "#     img1 = mpimg.imread(img)\n",
    "#     plt.figure(figsize=(8, 8)) \n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img1)\n",
    "#     plt.savefig('img1.png', bbox_inches=\"tight\", pad_inches=0, transparent= True)\n",
    "\n",
    "\n",
    "#     fig = plt.figure(figsize=(12,14),frameon=False)\n",
    "#     ax = fig.subplots(10, 1)\n",
    "#     fig.tight_layout()\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features[:,4097] \n",
    "#     ax[0].plot(x,y, linewidth=2.0)\n",
    "#     ax[0].locator_params(axis='y', nbins=3)\n",
    "#     ax[0].set_ylabel('Face Area', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     # h = ax[0].set(xlabel='x-label', ylabel='y-label',labelpad=20)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4098] \n",
    "#     ax[1].plot(x,y, linewidth=2.0)\n",
    "#     ax[1].locator_params(axis='y', nbins=3)\n",
    "#     ax[1].set_ylabel('Roll', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4099] \n",
    "#     ax[2].plot(x,y, linewidth=2.0)\n",
    "#     ax[2].locator_params(axis='y', nbins=3)\n",
    "#     ax[2].set_ylabel('Pitch', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4100] \n",
    "#     ax[3].plot(x,y, linewidth=2.0)\n",
    "#     ax[3].locator_params(axis='y', nbins=3)\n",
    "#     ax[3].set_ylabel('Yaw', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4101] \n",
    "#     ax[4].plot(x,y, linewidth=2.0)\n",
    "#     ax[4].locator_params(axis='y', nbins=3)\n",
    "#     ax[4].set_ylabel('EyeGaze_X', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4102] \n",
    "#     ax[5].plot(x,y, linewidth=2.0)\n",
    "#     ax[5].locator_params(axis='y', nbins=3)\n",
    "#     ax[5].set_ylabel('EyeGaze_Y', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4103] \n",
    "#     ax[6].plot(x,y, linewidth=2.0)\n",
    "#     ax[6].locator_params(axis='y', nbins=3)\n",
    "#     ax[6].set_ylabel('Phone', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4104] \n",
    "#     ax[7].plot(x,y, linewidth=2.0)\n",
    "#     ax[7].locator_params(axis='y', nbins=3)\n",
    "#     ax[7].set_ylabel('Seatbelt', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4106] \n",
    "#     ax[8].plot(x,y, linewidth=2.0)\n",
    "#     ax[8].locator_params(axis='y', nbins=3)\n",
    "#     ax[8].set_ylabel('EAR', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     x = np.linspace(0, 1, 52)\n",
    "#     y = video_features_combined[0,:,4106] \n",
    "#     ax[9].plot(x,y, linewidth=2.0)\n",
    "#     ax[9].locator_params(axis='y', nbins=3)\n",
    "#     ax[9].set_ylabel('MAR', rotation=0, fontsize=15, labelpad=60)\n",
    "\n",
    "#     fig.savefig('img2.png',bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dynamic_videos(video, ground_truth):\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     plt.style.use('dark_background')\n",
    "    \n",
    "#     for i in range(52):\n",
    "#         img1 = cv2.imread('dataset/output_'+str(i+1).zfill(5)+'.png')\n",
    "        \n",
    "#         img2 = \n",
    "#         img3 = np.concatenate((img1,img2), axis =1)\n",
    "#         # img4 = np.zeros((int(img3.shape[0]/2), int(img3.shape[1]), int(img3.shape[2])), np.uint8)\n",
    "\n",
    "#         # img5 = np.concatenate((img1,img2), axis =0)\n",
    "#         #Display the image\n",
    "#         plt.figure(figsize=(8, 10))\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(img3)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = video_names(ground_truth_combined)\n",
    "k =0\n",
    "for i in range(1):\n",
    "    k = i*20\n",
    "    !ffmpeg -i \"{x[k]}\"   -loglevel panic dataset/output_%05d.png\n",
    "    create_dynamic_videos(video_features_combined[k], ground_truth_combined[k])\n",
    "    print(\"\\n \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to literal (<ipython-input-51-f853184ec4d4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-f853184ec4d4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    temp, temp1 =[2,3,4], temp2 =[1,2]\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to literal\n"
     ]
    }
   ],
   "source": [
    "temp, temp1 =[2,3,4], temp2 =[1,2]\n",
    "temp.append((temp1,temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-50-93ef8a42666d>, line 134)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-93ef8a42666d>\"\u001b[0;36m, line \u001b[0;32m134\u001b[0m\n\u001b[0;31m    fig.savefig('faltu/img2_'+str(i+1)+'.png', pad_inches=0)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# plt.style.use('classic')\n",
    "# # for i in range(52):\n",
    "# #     plt.style.use('dark_background')\n",
    "# #     img1 = mpimg.imread('dataset/output_'+str(i+1).zfill(5)+'.png')\n",
    "# #     plt.figure(figsize=(8, 8)) \n",
    "# #     plt.axis('off')\n",
    "# #     plt.imshow(img1)\n",
    "# #     plt.savefig('faltu/img1_'+str(i+1)+'.png', bbox_inches=\"tight\", pad_inches=0, transparent= True)\n",
    "\n",
    "\n",
    "# xdata1 = []; ydata1 = []; \n",
    "# xdata2 = []; ydata2 = [];\n",
    "# xdata3 = []; ydata3 = [];\n",
    "# xdata4 = []; ydata4 = [];\n",
    "# xdata5 = []; ydata5 = [];\n",
    "# xdata6 = []; ydata6 = [];\n",
    "# xdata7 = []; ydata7 = [];\n",
    "# xdata8 = []; ydata8 = [];\n",
    "# xdata9 = []; ydata9 = [];\n",
    "# xdata10 = []; ydata10 = [];\n",
    "# #plt.show() \n",
    "\n",
    "# for i in range(52):\n",
    "\n",
    "#     fig = plt.figure(figsize=(6,7),frameon=False)\n",
    "#     ax = fig.subplots(10, 1)\n",
    "#     fig.tight_layout()\n",
    "\n",
    "#     ax[0].set_xlim(0, 52)\n",
    "#     ax[0].set_ylim(0, 329400)\n",
    "#     ax[0].locator_params(axis='y', nbins=5)\n",
    "#     ax[0].set_ylabel('Face Area', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[0].plot(xdata1, ydata1, 'r-')\n",
    "#     xdata1.append(i)\n",
    "#     ydata1.append(video_features_combined[0,i,4097])\n",
    "#     line.set_xdata(xdata1)\n",
    "#     line.set_ydata(ydata1)\n",
    "\n",
    "#     ax[1].set_xlim(0, 52)\n",
    "#     ax[1].set_ylim(-180, 180)\n",
    "#     ax[1].locator_params(axis='y', nbins=5)\n",
    "#     ax[1].set_ylabel('Roll', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[1].plot(xdata2, ydata2, 'r-')\n",
    "#     xdata2.append(i)\n",
    "#     ydata2.append(video_features_combined[0,i,4098])\n",
    "#     line.set_xdata(xdata2)\n",
    "#     line.set_ydata(ydata2)\n",
    "    \n",
    "    \n",
    "#     ax[2].set_xlim(0, 52)\n",
    "#     ax[2].set_ylim(-180, 180)\n",
    "#     ax[2].locator_params(axis='y', nbins=5)\n",
    "#     ax[2].set_ylabel('Pitch', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[2].plot(xdata3, ydata3, 'r-')\n",
    "#     xdata3.append(i)\n",
    "#     ydata3.append(video_features_combined[0,i,4099])\n",
    "#     line.set_xdata(xdata3)\n",
    "#     line.set_ydata(ydata3)\n",
    "    \n",
    "#     ax[3].set_xlim(0, 52)\n",
    "#     ax[3].set_ylim(-180, 180)\n",
    "#     ax[3].locator_params(axis='y', nbins=5)\n",
    "#     ax[3].set_ylabel('Yaw', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[3].plot(xdata4, ydata4, 'r-')\n",
    "#     xdata4.append(i)\n",
    "#     ydata4.append(video_features_combined[0,i,4100])\n",
    "#     line.set_xdata(xdata4)\n",
    "#     line.set_ydata(ydata4)\n",
    "    \n",
    "    \n",
    "#     ax[4].set_xlim(0, 52)\n",
    "#     ax[4].set_ylim(-180, 180)\n",
    "#     ax[4].locator_params(axis='y', nbins=5)\n",
    "#     ax[4].set_ylabel('EyeGaze_X', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[4].plot(xdata5, ydata5, 'r-')\n",
    "#     xdata5.append(i)\n",
    "#     ydata5.append(video_features_combined[0,i,4101])\n",
    "#     line.set_xdata(xdata5)\n",
    "#     line.set_ydata(ydata5)\n",
    "    \n",
    "#     ax[5].set_xlim(0, 52)\n",
    "#     ax[5].set_ylim(-180, 180)\n",
    "#     ax[5].locator_params(axis='y', nbins=5)\n",
    "#     ax[5].set_ylabel('EyeGaze_Y', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[5].plot(xdata6, ydata6, 'r-')\n",
    "#     xdata6.append(i)\n",
    "#     ydata6.append(video_features_combined[0,i,4102])\n",
    "#     line.set_xdata(xdata6)\n",
    "#     line.set_ydata(ydata6)\n",
    "    \n",
    "#     ax[6].set_xlim(0, 52)\n",
    "#     ax[6].set_ylim(0,1)\n",
    "#     ax[6].locator_params(axis='y', nbins=5)\n",
    "#     ax[6].set_ylabel('Phone', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[6].plot(xdata7, ydata7, 'r-')\n",
    "#     xdata7.append(i)\n",
    "#     ydata7.append(video_features_combined[0,i,4103])\n",
    "#     line.set_xdata(xdata7)\n",
    "#     line.set_ydata(ydata7)\n",
    "    \n",
    "#     ax[7].set_xlim(0, 52)\n",
    "#     ax[7].set_ylim(0,1)\n",
    "#     ax[7].locator_params(axis='y', nbins=5)\n",
    "#     ax[7].set_ylabel('Seatbelt', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[7].plot(xdata8, ydata8, 'r-')\n",
    "#     xdata8.append(i)\n",
    "#     ydata8.append(video_features_combined[0,i,4104])\n",
    "#     line.set_xdata(xdata8)\n",
    "#     line.set_ydata(ydata8)\n",
    "    \n",
    "    \n",
    "#     ax[8].set_xlim(0, 52)\n",
    "#     ax[8].set_ylim(0,10)\n",
    "#     ax[8].locator_params(axis='y', nbins=5)\n",
    "#     ax[8].set_ylabel('EAR', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[8].plot(xdata9, ydata9, 'r-', )\n",
    "#     xdata9.append(i)\n",
    "#     ydata9.append(video_features_combined[0,i,4106])\n",
    "#     line.set_xdata(xdata9)\n",
    "#     line.set_ydata(ydata9)\n",
    "    \n",
    "#     ax[9].set_xlim(0, 52)\n",
    "#     ax[9].set_ylim(0,10)\n",
    "#     ax[9].locator_params(axis='y', nbins=5)\n",
    "#     ax[9].set_ylabel('MAR', rotation=0, fontsize=15, labelpad=60)\n",
    "#     line, = ax[9].plot(xdata10, ydata10, 'r-')\n",
    "#     xdata10.append(i)\n",
    "#     ydata10.append(video_features_combined[0,i,4107])\n",
    "#     line.set_xdata(xdata10)\n",
    "#     line.set_ydata(ydata10)\n",
    "#   fig.savefig('faltu/img2_'+str(i+1)+'.png', pad_inches=0)\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
